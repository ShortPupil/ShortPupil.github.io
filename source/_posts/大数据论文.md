---
title: 大数据论文课程学习
copyright: false
tags: booknote
categories: 读书笔记
abbrlink: ff0a1714
date: 2022-02-01 18:57:44
---



# 学习课程 

[大数据经典论文解读 (geekbang.org)](https://time.geekbang.org/column/intro/100091101)

# 何为大数据

## 核心理念

wiki解释：[Big data - Wikipedia](https://en.wikipedia.org/wiki/Big_data)

即传统数据处理应用软件时，不足以处理的大的或者复杂的数据集的术语。换句话说，就是**技术上的老办法行不通了，必须使用新办法才能处理的数据**就叫大数据。

1. **能够伸缩到一千台服务器以上的分布式数据处理集群的技术**
   - 传统的并行数据库技术尝试处理海量数据，但这些并行数据库单个集群只有**几十数量级的服务器**
   - 2003年，**Google 的 GFS 的论文**，单个集群里就可以有**上千数量级的节点**
2. **这个上千个节点的集群，是采用廉价的 PC 架构搭建起来的。**
   - 不用超算或专用存储设备，“大数据”技术**在硬件层面，是完全架设在开放的 PC 架构下的**
3. **“把数据中心当作是一台计算机”（Datacenter as a Computer）。**
   - 所有的“大数据”框架，都希望就算没有“大数据”底层技术知识的工程师，也能很容易地处理海量数据。
4. 总结：大型集群让处理海量数据变得**“可能”**；基于开放的 PC 架构，让处理海量数据变得“便宜”；而优秀的封装和抽象，则是让处理海量数据变得**“容易”**。这也是现在谁都能用上大数据技术的基础。



## 大数据的三驾马车

### 三个核心架构

- **存储 GFS**

  - 核心功能
    - 存储数据——分布式文件系统
    - 并发写入——顺序写入
  - 不足和缺陷
    - 缺乏高可用性
    - “至少一次”的弱一致性

- **计算 MapReduce**——通过借鉴 Lisp，Google 利用简单的 Map 和 Reduce 两个函数，对于海量数据计算做了一次抽象

  - 核心功能
    - 数据本地化的并行机损
    - 系统容错和自动恢复

  - 不足和缺陷
    - 计算模型简单
    - 海量硬盘读写

- **在线服务 Bigtable** ——直接使用 GFS作为底层存储，来做好集群的分片调度，以及利用 **MemTable+SSTable 的底层存储格式**，来解决大集群、机械硬盘下的高性能的随机读写问题。

  - 核心功能
    - 在线服务
    - 高性能随机读写
    - 自动调度和分片
  - 不足和缺陷
    - 缺少Schema
    - 缺少跨行事务

  

  - 核心功能
    - 在线服务
    - 高性能随机读写
    - 自动调度和分片
  - 不足和缺陷
    - 缺少Schema
    - 缺少跨行事务

### 两个基础设施

- 一致性问题：
  - 实现了 Paxos 算法的 **Chubby 锁服务**——保障数据一致性的分布式锁
- 系统之间通信问题 + 数据存储格式化问题：
  - RPC：数据序列化和分布式系统之间通信的实现——通过 Thrift 序列化：我们要预知未来才能向后兼容吗？

## 三家马车的进化方向

一个新系统的设计当然不能用一句话概括，也不是理所当然如此。**任何一个新系统都是为了解决前一个系统的不足之处**。

![image-20220301231317621](C:\Users\m1885\AppData\Roaming\Typora\typora-user-images\image-20220301231317621.png)

![image-20220301231607528](C:\Users\m1885\AppData\Roaming\Typora\typora-user-images\image-20220301231607528.png)

![image-20220301231725889](C:\Users\m1885\AppData\Roaming\Typora\typora-user-images\image-20220301231725889.png)

## 小结 论文清单



# 知识网络

![image-20220301232105100](C:\Users\m1885\AppData\Roaming\Typora\typora-user-images\image-20220301232105100.png)

